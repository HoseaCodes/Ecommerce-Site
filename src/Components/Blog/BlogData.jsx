import blog from '../../Images/blog.png'
import blog2 from '../../Images/blog2.png'
import blog3 from '../../Images/blog3.png'

export const blogData = [
    {
        id: 1,
        category: 'Health',
        name: 'Bash Commands',
        date: 'Dec. 14, 2020',
        img: blog,
        title: 'How to navigate through your terminal',
        type: 'Software Engineer',
        info: ['Bash is a command processor that tyipcally runs in a text window where the user types commands that cause actions. I am sure you have seen a terminal window before. It is that window that gives you that Steve Jobs or early 90s Microsoft feeling when you look at it.',
            'If looks could kill I am sure the command line has taken many people out of their tech lives. For the most part most of us are not use to seeing a computer program that does not have a user friendly experience. That is right the terminal is the same concept as your favorite website. The difference is that your terminal was created to aid your os, operating system, to do it job.',
            'On top of the overwhelming looks of the command line there are over 150+ commands. As a new developer that can be daunting but lucky enough develops love to help one another out. So let\'s breakdown what you will need in order to start using bash commands. I also have a list of commands on my git hub to help new developers',
            'At this point you may be thinking I can do everything you are talking about without using the terminal. This is very true but the benefit is doing this from one centrlized location which means you will save a lot of time. As you grow you will begin to realize become more effecient is a core concept to being a developer. Commands give developers the tools to manipulate every aspect of their device and systems they use. They can do this through a list of options that come with every command to assist with any type of issue you may have. Working in the comamand line is essential if you plan on developing at any capcity.',
        ],
        subHeading: ['What is bash?',
            'How relavent is the command line?',
        ],
        tags: ['Bash', 'Software Engineer'],
        link: './bash',


    },
    {
        id: 2,
        category: 'Health',
        name: 'Big O Notation',
        date: 'Dec. 23, 2020',
        img: blog2,
        title: 'Time & Space Complexity',
        type: 'Software Engineer',
        info: ['Big O time is the lanuage and metric we use to describe the efficiency of algorithms. The Big O notation defines an upper bound of an algorithm, it bounds a function only from above. In general cases, we mainly used to measure and compare the worst-case theoretical running time complexities of algorithms for the performance analysis. The fastest possible running time for any algorithm is O(1), commonly referred to as Constant Running Time. In this case, the algorithm always takes the same amount of time to execute, regardless of the input size. This is the ideal runtime for an algorithm, but it’s rarely achievable. In actual cases, the performance (Runtime) of an algorithm depends on n, that is the size of the input or the number of operations is required for each input item. ',
            '1.) Figure out what the input is and what n represents.\n 2.) Express the maximum number of operations, the algorithm performs in terms of n. \n 3.) Eliminate all excluding the highest order terms. \n 4.) Remove all the constant factors.',
            'Typically, we are usually interested in the worst case: what is the maximum number of operations that might be performed for a given problem size. For example, inserting an element into an array, we have to move the current element and all of the elements that come after it one place to the right in the array. In the worst case, inserting at the beginning of the array, all of the elements in the array must be moved. Therefore, in the worst case, the time for insertion is proportional to the number of elements in the array, and we say that the worst-case time for the insertion operation is linear in the number of elements in the array. For a linear-time algorithm, if the problem size doubles, the number of operations also doubles.',
            'What Big O notation doesn\'t tell you is the speed of the algorithm in seconds. There are way too many factors that influence the time an algorithm takes to run. Instead, you\'ll use Big O notation to compare different algorithms by the number of operations they make.',
            'Firstly, the implementation of the program is responsible for memory usage. For example, we can assume that recursive implementation always reserves more memory than the corresponding iterative implementation of a particular problem. And the other one is n, the input size or the amount of storage required for each item. For example, a simple algorithm with a high amount of input size can consume more memory than a complex algorithm with less amount of input size. In general for an algorithm, space efficiency and time efficiency reach at two opposite ends and each point in between them has a certain time and space efficiency. So, the more time efficiency you have, the less space efficiency you have and vice versa.',
        ],
        subHeading: ['Upper Bound of the Algorithm',
            'How to find the time complexity',
            'The algorithms can be classified as follows from the best-to-worst performance (Running Time Complexity):',
            'Analyze Runtime',
            'Memory Footprint of the algorithm or Space Complexity'
        ],
        tags: ['BigO', 'Time', 'Space'],
        link: './bigo',
    },
    {
        id: 3,
        category: 'Health',
        name: 'Big O Notation',
        date: 'Dec. 23, 2020',
        img: blog3,
        title: 'Time & Space Complexity',
        type: 'Software Engineer',
        info: ['Big O time is the lanuage and metric we use to describe the efficiency of algorithms. The Big O notation defines an upper bound of an algorithm, it bounds a function only from above. In general cases, we mainly used to measure and compare the worst-case theoretical running time complexities of algorithms for the performance analysis. The fastest possible running time for any algorithm is O(1), commonly referred to as Constant Running Time. In this case, the algorithm always takes the same amount of time to execute, regardless of the input size. This is the ideal runtime for an algorithm, but it’s rarely achievable. In actual cases, the performance (Runtime) of an algorithm depends on n, that is the size of the input or the number of operations is required for each input item. ',
            '1.) Figure out what the input is and what n represents.\n 2.) Express the maximum number of operations, the algorithm performs in terms of n. \n 3.) Eliminate all excluding the highest order terms. \n 4.) Remove all the constant factors.',
            'Typically, we are usually interested in the worst case: what is the maximum number of operations that might be performed for a given problem size. For example, inserting an element into an array, we have to move the current element and all of the elements that come after it one place to the right in the array. In the worst case, inserting at the beginning of the array, all of the elements in the array must be moved. Therefore, in the worst case, the time for insertion is proportional to the number of elements in the array, and we say that the worst-case time for the insertion operation is linear in the number of elements in the array. For a linear-time algorithm, if the problem size doubles, the number of operations also doubles.',
            'What Big O notation doesn\'t tell you is the speed of the algorithm in seconds. There are way too many factors that influence the time an algorithm takes to run. Instead, you\'ll use Big O notation to compare different algorithms by the number of operations they make.',
            'Firstly, the implementation of the program is responsible for memory usage. For example, we can assume that recursive implementation always reserves more memory than the corresponding iterative implementation of a particular problem. And the other one is n, the input size or the amount of storage required for each item. For example, a simple algorithm with a high amount of input size can consume more memory than a complex algorithm with less amount of input size. In general for an algorithm, space efficiency and time efficiency reach at two opposite ends and each point in between them has a certain time and space efficiency. So, the more time efficiency you have, the less space efficiency you have and vice versa.',
        ],
        subHeading: ['Upper Bound of the Algorithm',
            'How to find the time complexity',
            'The algorithms can be classified as follows from the best-to-worst performance (Running Time Complexity):',
            'Analyze Runtime',
            'Memory Footprint of the algorithm or Space Complexity'
        ],
        tags: ['BigO', 'Time', 'Space'],
        link: './bigo',
    },
    {
        id: 3,
        category: 'Health',
        name: 'Big O Notation',
        date: 'Dec. 23, 2020',
        img: blog3,
        title: 'Time & Space Complexity',
        type: 'Software Engineer',
        info: ['Big O time is the lanuage and metric we use to describe the efficiency of algorithms. The Big O notation defines an upper bound of an algorithm, it bounds a function only from above. In general cases, we mainly used to measure and compare the worst-case theoretical running time complexities of algorithms for the performance analysis. The fastest possible running time for any algorithm is O(1), commonly referred to as Constant Running Time. In this case, the algorithm always takes the same amount of time to execute, regardless of the input size. This is the ideal runtime for an algorithm, but it’s rarely achievable. In actual cases, the performance (Runtime) of an algorithm depends on n, that is the size of the input or the number of operations is required for each input item. ',
            '1.) Figure out what the input is and what n represents.\n 2.) Express the maximum number of operations, the algorithm performs in terms of n. \n 3.) Eliminate all excluding the highest order terms. \n 4.) Remove all the constant factors.',
            'Typically, we are usually interested in the worst case: what is the maximum number of operations that might be performed for a given problem size. For example, inserting an element into an array, we have to move the current element and all of the elements that come after it one place to the right in the array. In the worst case, inserting at the beginning of the array, all of the elements in the array must be moved. Therefore, in the worst case, the time for insertion is proportional to the number of elements in the array, and we say that the worst-case time for the insertion operation is linear in the number of elements in the array. For a linear-time algorithm, if the problem size doubles, the number of operations also doubles.',
            'What Big O notation doesn\'t tell you is the speed of the algorithm in seconds. There are way too many factors that influence the time an algorithm takes to run. Instead, you\'ll use Big O notation to compare different algorithms by the number of operations they make.',
            'Firstly, the implementation of the program is responsible for memory usage. For example, we can assume that recursive implementation always reserves more memory than the corresponding iterative implementation of a particular problem. And the other one is n, the input size or the amount of storage required for each item. For example, a simple algorithm with a high amount of input size can consume more memory than a complex algorithm with less amount of input size. In general for an algorithm, space efficiency and time efficiency reach at two opposite ends and each point in between them has a certain time and space efficiency. So, the more time efficiency you have, the less space efficiency you have and vice versa.',
        ],
        subHeading: ['Upper Bound of the Algorithm',
            'How to find the time complexity',
            'The algorithms can be classified as follows from the best-to-worst performance (Running Time Complexity):',
            'Analyze Runtime',
            'Memory Footprint of the algorithm or Space Complexity'
        ],
        tags: ['BigO', 'Time', 'Space'],
        link: './bigo',
    },
    {
        id: 3,
        category: 'Health',
        name: 'Big O Notation',
        date: 'Dec. 23, 2020',
        img: blog3,
        title: 'Time & Space Complexity',
        type: 'Software Engineer',
        info: ['Big O time is the lanuage and metric we use to describe the efficiency of algorithms. The Big O notation defines an upper bound of an algorithm, it bounds a function only from above. In general cases, we mainly used to measure and compare the worst-case theoretical running time complexities of algorithms for the performance analysis. The fastest possible running time for any algorithm is O(1), commonly referred to as Constant Running Time. In this case, the algorithm always takes the same amount of time to execute, regardless of the input size. This is the ideal runtime for an algorithm, but it’s rarely achievable. In actual cases, the performance (Runtime) of an algorithm depends on n, that is the size of the input or the number of operations is required for each input item. ',
            '1.) Figure out what the input is and what n represents.\n 2.) Express the maximum number of operations, the algorithm performs in terms of n. \n 3.) Eliminate all excluding the highest order terms. \n 4.) Remove all the constant factors.',
            'Typically, we are usually interested in the worst case: what is the maximum number of operations that might be performed for a given problem size. For example, inserting an element into an array, we have to move the current element and all of the elements that come after it one place to the right in the array. In the worst case, inserting at the beginning of the array, all of the elements in the array must be moved. Therefore, in the worst case, the time for insertion is proportional to the number of elements in the array, and we say that the worst-case time for the insertion operation is linear in the number of elements in the array. For a linear-time algorithm, if the problem size doubles, the number of operations also doubles.',
            'What Big O notation doesn\'t tell you is the speed of the algorithm in seconds. There are way too many factors that influence the time an algorithm takes to run. Instead, you\'ll use Big O notation to compare different algorithms by the number of operations they make.',
            'Firstly, the implementation of the program is responsible for memory usage. For example, we can assume that recursive implementation always reserves more memory than the corresponding iterative implementation of a particular problem. And the other one is n, the input size or the amount of storage required for each item. For example, a simple algorithm with a high amount of input size can consume more memory than a complex algorithm with less amount of input size. In general for an algorithm, space efficiency and time efficiency reach at two opposite ends and each point in between them has a certain time and space efficiency. So, the more time efficiency you have, the less space efficiency you have and vice versa.',
        ],
        subHeading: ['Upper Bound of the Algorithm',
            'How to find the time complexity',
            'The algorithms can be classified as follows from the best-to-worst performance (Running Time Complexity):',
            'Analyze Runtime',
            'Memory Footprint of the algorithm or Space Complexity'
        ],
        tags: ['BigO', 'Time', 'Space'],
        link: './bigo',
    },
    {
        id: 3,
        category: 'Health',
        name: 'Big O Notation',
        date: 'Dec. 23, 2020',
        img: blog3,
        title: 'Time & Space Complexity',
        type: 'Software Engineer',
        info: ['Big O time is the lanuage and metric we use to describe the efficiency of algorithms. The Big O notation defines an upper bound of an algorithm, it bounds a function only from above. In general cases, we mainly used to measure and compare the worst-case theoretical running time complexities of algorithms for the performance analysis. The fastest possible running time for any algorithm is O(1), commonly referred to as Constant Running Time. In this case, the algorithm always takes the same amount of time to execute, regardless of the input size. This is the ideal runtime for an algorithm, but it’s rarely achievable. In actual cases, the performance (Runtime) of an algorithm depends on n, that is the size of the input or the number of operations is required for each input item. ',
            '1.) Figure out what the input is and what n represents.\n 2.) Express the maximum number of operations, the algorithm performs in terms of n. \n 3.) Eliminate all excluding the highest order terms. \n 4.) Remove all the constant factors.',
            'Typically, we are usually interested in the worst case: what is the maximum number of operations that might be performed for a given problem size. For example, inserting an element into an array, we have to move the current element and all of the elements that come after it one place to the right in the array. In the worst case, inserting at the beginning of the array, all of the elements in the array must be moved. Therefore, in the worst case, the time for insertion is proportional to the number of elements in the array, and we say that the worst-case time for the insertion operation is linear in the number of elements in the array. For a linear-time algorithm, if the problem size doubles, the number of operations also doubles.',
            'What Big O notation doesn\'t tell you is the speed of the algorithm in seconds. There are way too many factors that influence the time an algorithm takes to run. Instead, you\'ll use Big O notation to compare different algorithms by the number of operations they make.',
            'Firstly, the implementation of the program is responsible for memory usage. For example, we can assume that recursive implementation always reserves more memory than the corresponding iterative implementation of a particular problem. And the other one is n, the input size or the amount of storage required for each item. For example, a simple algorithm with a high amount of input size can consume more memory than a complex algorithm with less amount of input size. In general for an algorithm, space efficiency and time efficiency reach at two opposite ends and each point in between them has a certain time and space efficiency. So, the more time efficiency you have, the less space efficiency you have and vice versa.',
        ],
        subHeading: ['Upper Bound of the Algorithm',
            'How to find the time complexity',
            'The algorithms can be classified as follows from the best-to-worst performance (Running Time Complexity):',
            'Analyze Runtime',
            'Memory Footprint of the algorithm or Space Complexity'
        ],
        tags: ['BigO', 'Time', 'Space'],
        link: './bigo',
    },
]